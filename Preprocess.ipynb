{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Train/Valid/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UserID::Gender::Age::Occupation::Zip-code\n",
    "# MovieID::Title::Genres\n",
    "# UserID::MovieID::Rating::Timestamp (5-star scale)\n",
    "\n",
    "# Importing the dataset\n",
    "#movies = pd.read_csv('./data/ml_1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "#users = pd.read_csv('./data/ml_1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('./data/ml_100k/u.data', sep = '\\t', header = None, engine = 'python', encoding = 'latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = len(ratings)\n",
    "ratings = ratings.sample(frac=1)\n",
    "\n",
    "len_train = int(total_length*0.85)\n",
    "len_val   = int(total_length*0.9)\n",
    "\n",
    "rating_train = ratings[:len_train]\n",
    "rating_val   = ratings[len_train:len_val]\n",
    "rating_test  = ratings[len_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users  = 943#6040\n",
    "num_items = 1682#3706\n",
    "rating_cnt = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "item_dict = {}\n",
    "\n",
    "rating_sum = torch.zeros(rating_cnt, num_users, num_items)\n",
    "for i, ratings in enumerate([rating_train, rating_val, rating_test]):\n",
    "    rating_mtx = torch.zeros(rating_cnt, num_users, num_items)\n",
    "    \n",
    "    for index, row in ratings.iterrows():\n",
    "        u = int(row[0])-1\n",
    "        v = int(row[1])-1\n",
    "        r = int(row[2])-1\n",
    "        \n",
    "        if user_dict.get(u) is not None:\n",
    "            u = user_dict[u]\n",
    "        else:\n",
    "            user_dict[u] = len(user_dict)\n",
    "            u = user_dict[u]\n",
    "        \n",
    "        if item_dict.get(v) is not None:\n",
    "            v = item_dict[v]\n",
    "        else:\n",
    "            item_dict[v] = len(item_dict)\n",
    "            v = item_dict[v]\n",
    "        \n",
    "        rating_mtx[r, u, v] = 1\n",
    "    \n",
    "    \n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    '''\n",
    "    rowsum = torch.sum(torch.sum(rating_mtx, 0),1)\n",
    "    r_inv = torch.pow(rowsum, -1).view(-1)\n",
    "    r_inv[torch.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = torch.diag(r_inv)\n",
    "    mx = torch.matmul(rating_mtx.permute(0,2,1), r_mat_inv)\n",
    "    mx = torch.stack((mx.permute(0,2,1), rating_mtx), 0)\n",
    "    '''\n",
    "    \n",
    "    rating_sum += rating_mtx\n",
    "\n",
    "    #torch.save(mx, './data/rating_norm_%d.pkl'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682, torch.Size([71, 6000, 6000]), torch.Size([5, 3000, 3000]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_dict), len(item_dict), mx.size(), rating_mtx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rating_sum\n",
    "mx = torch.cat((torch.cat((torch.zeros(A.size(0),A.size(1),A.size(1)), A), 2),\n",
    "                torch.cat((A.permute(0,2,1), torch.zeros(A.size(0),A.size(2),A.size(2))), 2)), 1)\n",
    "\n",
    "\n",
    "square = []\n",
    "for i, x in enumerate(mx):\n",
    "    square.append(torch.mm(x,x))\n",
    "    \n",
    "square = torch.sum(torch.stack(square, 0), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10603991666666666\n",
      "3817437 6000 6000 36000000\n"
     ]
    }
   ],
   "source": [
    "print(len(torch.nonzero(square))/(square.size(0)*square.size(1)))\n",
    "print(len(torch.nonzero(square)), square.size(0), square.size(1), square.size(1)*square.size(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data):\n",
    "    \"\"\"\n",
    "    Map data to proper indices in case they are not in a continues [0, N) range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.int32 arrays\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mapped_data : np.int32 arrays\n",
    "    n : length of mapped_data\n",
    "\n",
    "    \"\"\"\n",
    "    uniq = list(set(data))\n",
    "\n",
    "    id_dict = {old: new for new, old in enumerate(sorted(uniq))}\n",
    "    data = np.array(list(map(lambda x: id_dict[x], data)))\n",
    "    n = len(uniq)\n",
    "\n",
    "    return data, id_dict, n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongqyu/py3env/lib/python3.5/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "sep = r'\\:\\:'\n",
    "filename = './data/ml_1m/ratings.dat'\n",
    "dtypes = {\n",
    "            'u_nodes': np.int64, 'v_nodes': np.int64,\n",
    "            'ratings': np.float32, 'timestamp': np.float64}\n",
    "\n",
    "# use engine='python' to ignore warning about switching to python backend when using regexp for sep\n",
    "data = pd.read_csv(filename, sep=sep, header=None,\n",
    "                   names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], converters=dtypes, engine='python')\n",
    "\n",
    "# shuffle here like cf-nade paper with python's own random class\n",
    "# make sure to convert to list, otherwise random.shuffle acts weird on it without a warning\n",
    "data_array = data.as_matrix().tolist()\n",
    "random.seed(seed)\n",
    "random.shuffle(data_array)\n",
    "data_array = np.array(data_array)\n",
    "\n",
    "u_nodes_ratings = data_array[:, 0].astype(dtypes['u_nodes'])\n",
    "v_nodes_ratings = data_array[:, 1].astype(dtypes['v_nodes'])\n",
    "ratings = data_array[:, 2].astype(dtypes['ratings'])\n",
    "\n",
    "u_nodes_ratings, u_dict, num_users = map_data(u_nodes_ratings)\n",
    "v_nodes_ratings, v_dict, num_items = map_data(v_nodes_ratings)\n",
    "\n",
    "u_nodes_ratings, v_nodes_ratings = u_nodes_ratings.astype(np.int64), v_nodes_ratings.astype(np.int64)\n",
    "ratings = ratings.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_nodes = u_nodes_ratings\n",
    "v_nodes = v_nodes_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_rating = -1\n",
    "num_users = 6040\n",
    "num_items = 3706\n",
    "\n",
    "rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
    "\n",
    "labels = np.full((num_users, num_items), neutral_rating, dtype=np.int32)\n",
    "labels[u_nodes, v_nodes] = np.array([rating_dict[r] for r in ratings])\n",
    "labels = labels.reshape([-1])\n",
    "\n",
    "# number of test and validation edges\n",
    "num_test = int(np.ceil(ratings.shape[0] * 0.1))\n",
    "num_val = int(np.ceil(ratings.shape[0] * 0.9 * 0.05))\n",
    "num_train = ratings.shape[0] - num_val - num_test\n",
    "\n",
    "pairs_nonzero = np.array([[u, v] for u, v in zip(u_nodes, v_nodes)])\n",
    "\n",
    "idx_nonzero = np.array([u * num_items + v for u, v in pairs_nonzero])\n",
    "\n",
    "train_idx = idx_nonzero[0:num_train]\n",
    "val_idx = idx_nonzero[num_train:num_train + num_val]\n",
    "test_idx = idx_nonzero[num_train + num_val:]\n",
    "\n",
    "train_pairs_idx = pairs_nonzero[0:num_train]\n",
    "val_pairs_idx = pairs_nonzero[num_train:num_train + num_val]\n",
    "test_pairs_idx = pairs_nonzero[num_train + num_val:]\n",
    "\n",
    "u_test_idx, v_test_idx = test_pairs_idx.transpose()\n",
    "u_val_idx, v_val_idx = val_pairs_idx.transpose()\n",
    "u_train_idx, v_train_idx = train_pairs_idx.transpose()\n",
    "\n",
    "# create labels\n",
    "train_labels = labels[train_idx]\n",
    "val_labels = labels[val_idx]\n",
    "test_labels = labels[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate([zip(u_train_idx,v_train_idx,train_labels), \n",
    "                          zip(u_val_idx,v_val_idx,val_labels), \n",
    "                          zip(u_test_idx,v_test_idx,test_labels)]):\n",
    "    rating_mx = torch.zeros(len(rating_dict), num_users, num_items)\n",
    "    \n",
    "    for u, v, r in list(data):\n",
    "        rating_mx[r, u, v] = 1\n",
    "\n",
    "    torch.save(rating_mx, './data/ml_1m_%d.pkl'%i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flixster/Douban/YahooMusic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matlab_file(path_file, name_field):\n",
    "    db = h5py.File(path_file, 'r')\n",
    "    ds = db[name_field]\n",
    "    try:\n",
    "        if 'ir' in ds.keys():\n",
    "            data = np.asarray(ds['data'])\n",
    "            ir = np.asarray(ds['ir'])\n",
    "            jc = np.asarray(ds['jc'])\n",
    "            out = sp.csc_matrix((data, ir, jc)).astype(np.float32)\n",
    "    except AttributeError:\n",
    "        # Transpose in case is a dense matrix because of the row- vs column- major ordering between python and matlab\n",
    "        out = np.asarray(ds).astype(np.float32).T\n",
    "\n",
    "    db.close()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "dataset = 'douban'#'flixster'#yahoo_music'#'\n",
    "path_dataset = './data/{}/training_test_dataset.mat'.format(dataset)\n",
    "name_field= 'W_users'\n",
    "\n",
    "M = load_matlab_file(path_dataset, 'M')\n",
    "Otraining = load_matlab_file(path_dataset, 'Otraining')\n",
    "Otest = load_matlab_file(path_dataset, 'Otest')\n",
    "\n",
    "num_users = M.shape[0]\n",
    "num_items = M.shape[1]\n",
    "\n",
    "if dataset == 'flixster':\n",
    "    Wrow = load_matlab_file(path_dataset, 'W_users')\n",
    "    Wcol = load_matlab_file(path_dataset, 'W_movies')\n",
    "    u_features = Wrow\n",
    "    v_features = Wcol\n",
    "    # print(num_items, v_features.shape)\n",
    "    #v_features = np.eye(num_items)\n",
    "\n",
    "elif dataset == 'douban':\n",
    "    Wrow = load_matlab_file(path_dataset, 'W_users')\n",
    "    u_features = Wrow\n",
    "    v_features = np.eye(num_items)\n",
    "elif dataset == 'yahoo_music':\n",
    "    Wcol = load_matlab_file(path_dataset, 'W_tracks')\n",
    "    u_features = np.eye(num_users)\n",
    "    v_features = Wcol\n",
    "\n",
    "u_nodes_ratings = np.where(M)[0]\n",
    "v_nodes_ratings = np.where(M)[1]\n",
    "ratings = M[np.where(M)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users =  2999\n",
      "number of item =  3000\n"
     ]
    }
   ],
   "source": [
    "u_nodes_ratings, v_nodes_ratings = u_nodes_ratings.astype(np.int64), v_nodes_ratings.astype(np.int32)\n",
    "ratings = ratings.astype(np.float64)\n",
    "\n",
    "u_nodes = u_nodes_ratings\n",
    "v_nodes = v_nodes_ratings\n",
    "\n",
    "print('number of users = ', len(set(u_nodes)))\n",
    "print('number of item = ', len(set(v_nodes)))\n",
    "\n",
    "neutral_rating = 0 # int(np.ceil(np.float(num_classes)/2.)) - 1\n",
    "\n",
    "# assumes that ratings_train contains at least one example of every rating type\n",
    "rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
    "\n",
    "labels = np.full((num_users, num_items), neutral_rating, dtype=np.int32)\n",
    "labels[u_nodes, v_nodes] = np.array([rating_dict[r] for r in ratings])\n",
    "\n",
    "for i in range(len(u_nodes)):\n",
    "    assert(labels[u_nodes[i], v_nodes[i]] == rating_dict[ratings[i]])\n",
    "    \n",
    "labels = labels.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of test and validation edges\n",
    "\n",
    "num_train = np.where(Otraining)[0].shape[0]\n",
    "num_test = np.where(Otest)[0].shape[0]\n",
    "num_val = int(np.ceil(num_train * 0.2))\n",
    "num_train = num_train - num_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_nonzero_train = np.array([[u, v] for u, v in zip(np.where(Otraining)[0], np.where(Otraining)[1])])\n",
    "idx_nonzero_train = np.array([u * num_items + v for u, v in pairs_nonzero_train])\n",
    "\n",
    "pairs_nonzero_test = np.array([[u, v] for u, v in zip(np.where(Otest)[0], np.where(Otest)[1])])\n",
    "idx_nonzero_test = np.array([u * num_items + v for u, v in pairs_nonzero_test])\n",
    "\n",
    "# Internally shuffle training set (before splitting off validation set)\n",
    "rand_idx = list(range(len(idx_nonzero_train)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(rand_idx)\n",
    "idx_nonzero_train = idx_nonzero_train[rand_idx]\n",
    "pairs_nonzero_train = pairs_nonzero_train[rand_idx]\n",
    "\n",
    "idx_nonzero = np.concatenate([idx_nonzero_train, idx_nonzero_test], axis=0)\n",
    "pairs_nonzero = np.concatenate([pairs_nonzero_train, pairs_nonzero_test], axis=0)\n",
    "\n",
    "val_idx = idx_nonzero[0:num_val]\n",
    "train_idx = idx_nonzero[num_val:num_train + num_val]\n",
    "test_idx = idx_nonzero[num_train + num_val:]\n",
    "\n",
    "assert(len(test_idx) == num_test)\n",
    "\n",
    "val_pairs_idx = pairs_nonzero[0:num_val]\n",
    "train_pairs_idx = pairs_nonzero[num_val:num_train + num_val]\n",
    "test_pairs_idx = pairs_nonzero[num_train + num_val:]\n",
    "\n",
    "u_test_idx, v_test_idx = test_pairs_idx.transpose()\n",
    "u_val_idx, v_val_idx = val_pairs_idx.transpose()\n",
    "u_train_idx, v_train_idx = train_pairs_idx.transpose()\n",
    "\n",
    "# create labels\n",
    "train_labels = labels[train_idx]\n",
    "val_labels = labels[val_idx]\n",
    "test_labels = labels[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n"
     ]
    }
   ],
   "source": [
    "minimum = min(min(test_labels), min(train_labels), min(val_labels))\n",
    "maximum = max(max(test_labels), max(train_labels), max(val_labels))\n",
    "print(minimum, maximum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rating_train = zip(u_train_idx, v_train_idx, train_labels)\n",
    "rating_val = zip(u_val_idx, v_val_idx, val_labels)\n",
    "rating_test = zip(u_test_idx, v_test_idx, test_labels)\n",
    "\n",
    "rating_sum = torch.zeros((maximum-minimum+1, 3000, 3000))\n",
    "for i, ratings in enumerate([rating_train, rating_val, rating_test]):\n",
    "    rating_mtx = torch.zeros((maximum-minimum+1, 3000, 3000))\n",
    "    \n",
    "    for (u, v, r) in ratings:\n",
    "        \n",
    "        rating_mtx[r, u, v] = 1\n",
    "        \n",
    "    rating_sum += rating_mtx\n",
    "    #torch.save(rating_mtx, './data/%s_%d.pkl'%(dataset,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in train_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
